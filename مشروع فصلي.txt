"""
Ù†Ø¸Ø§Ù… Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø«ØºØ±Ø§Øª Ø§Ù„Ø£Ù…Ù†ÙŠØ© Ø§Ù„Ø°Ø§ØªÙŠ Ø§Ù„ØªØ¹Ù„Ù…
Ù…Ø´Ø±ÙˆØ¹ ØªØ®Ø±Ø¬ Ù…ØªÙ‚Ø¯Ù… - Ø¥Ù„ØºØ§Ø¡ Ø§Ù„ØªØ¯Ø®Ù„ Ø§Ù„Ø¨Ø´Ø±ÙŠ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„
"""

# ====================== Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ======================
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.distributions import Categorical, Normal
import gym
from gym import spaces
import matplotlib.pyplot as plt
import seaborn as sns
from collections import deque
import random
from datetime import datetime
import json
import pickle
import os
import warnings
import hashlib
import logging
import sys
import time
from tqdm import tqdm
import shutil
import csv

warnings.filterwarnings('ignore')

# ====================== Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© ======================
class SystemConfig:
    def __init__(self):
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ¹Ù„Ù…
        self.learning_rate = 0.001
        self.gamma = 0.99
        self.tau = 0.005
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        self.memory_size = 100000
        self.batch_size = 128
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø´Ø¨ÙƒØ©
        self.hidden_size = 256
        self.num_actions = 12
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        self.max_episodes = 2000
        self.max_steps = 200
        self.update_every = 50
        self.save_every = 100
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªÙƒÙŠÙ
        self.epsilon_start = 1.0
        self.epsilon_end = 0.01
        self.epsilon_decay = 0.995
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
        self.create_folders()
    
    def create_folders(self):
        folders = ['models', 'data', 'logs', 'reports', 'backups']
        for folder in folders:
            os.makedirs(folder, exist_ok=True)

# ====================== ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ø§ØªÙŠ ======================
class DataGenerator:
    def __init__(self):
        self.vulnerabilities = {
            'SQL Injection': {'severity': 9, 'complexity': 7, 'patterns': ['SELECT', 'UNION', 'OR 1=1']},
            'XSS': {'severity': 7, 'complexity': 6, 'patterns': ['<script>', 'alert', 'onload']},
            'RCE': {'severity': 10, 'complexity': 9, 'patterns': ['system(', 'exec(', 'eval(']},
            'LFI': {'severity': 8, 'complexity': 6, 'patterns': ['../', 'etc/passwd', 'include']},
            'SSRF': {'severity': 8, 'complexity': 7, 'patterns': ['localhost', '127.0.0.1', 'internal']}
        }
        
        self.systems = {
            'Web Server': {'ports': [80, 443, 8080], 'services': ['Apache', 'Nginx', 'IIS']},
            'Database': {'ports': [3306, 5432, 27017], 'services': ['MySQL', 'PostgreSQL', 'MongoDB']},
            'Application': {'ports': [3000, 5000, 8000], 'services': ['Node.js', 'Python', 'Java']},
            'File Server': {'ports': [21, 22, 445], 'services': ['FTP', 'SSH', 'SMB']},
            'Mail Server': {'ports': [25, 110, 143], 'services': ['SMTP', 'POP3', 'IMAP']}
        }
        
        self.patterns_learned = []
        
    def generate_system(self):
        system_type = random.choice(list(self.systems.keys()))
        system_info = self.systems[system_type]
        
        # ØªÙˆÙ„ÙŠØ¯ Ø¹Ø¯Ø¯ Ø¹Ø´ÙˆØ§Ø¦ÙŠ Ù…Ù† Ø§Ù„Ù…Ù†Ø§ÙØ° Ø§Ù„Ù…ÙØªÙˆØ­Ø©
        num_ports = random.randint(2, len(system_info['ports']))
        open_ports = random.sample(system_info['ports'], num_ports)
        
        # ØªÙˆÙ„ÙŠØ¯ Ø®Ø¯Ù…Ø§Øª
        services = random.sample(system_info['services'], random.randint(1, len(system_info['services'])))
        
        # ØªØ­Ø¯ÙŠØ¯ ÙˆØ¬ÙˆØ¯ Ø«ØºØ±Ø©
        has_vulnerability = random.random() > 0.3
        
        vulnerability = None
        vulnerability_type = None
        vulnerability_details = None
        
        if has_vulnerability:
            vulnerability_type = random.choice(list(self.vulnerabilities.keys()))
            vulnerability = self.vulnerabilities[vulnerability_type]
            
            # Ø¥Ù†Ø´Ø§Ø¡ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø«ØºØ±Ø©
            vulnerability_details = {
                'type': vulnerability_type,
                'severity': vulnerability['severity'],
                'complexity': vulnerability['complexity'],
                'pattern': random.choice(vulnerability['patterns']),
                'port': random.choice(open_ports) if open_ports else 80,
                'exploitable': random.random() > 0.4
            }
        
        system = {
            'id': f"SYS_{random.randint(1000, 9999)}",
            'type': system_type,
            'open_ports': open_ports,
            'services': services,
            'os': random.choice(['Linux', 'Windows', 'macOS']),
            'has_vulnerability': has_vulnerability,
            'vulnerability': vulnerability_details,
            'security_level': random.randint(1, 10),
            'firewall': random.random() > 0.5,
            'ids': random.random() > 0.7
        }
        
        return system
    
    def generate_dataset(self, num_samples=1000):
        dataset = []
        
        for i in range(num_samples):
            system = self.generate_system()
            dataset.append(system)
            
            # ØªØ¹Ù„Ù… Ø§Ù„Ø£Ù†Ù…Ø§Ø·
            if system['has_vulnerability']:
                pattern = {
                    'system_type': system['type'],
                    'vulnerability': system['vulnerability']['type'],
                    'port': system['vulnerability']['port'],
                    'service': random.choice(system['services'])
                }
                self.patterns_learned.append(pattern)
        
        return dataset
    
    def save_patterns(self, filename='data/patterns.json'):
        with open(filename, 'w') as f:
            json.dump(self.patterns_learned, f, indent=2)
    
    def load_patterns(self, filename='data/patterns.json'):
        if os.path.exists(filename):
            with open(filename, 'r') as f:
                self.patterns_learned = json.load(f)

# ====================== Ø¨ÙŠØ¦Ø© Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø¹Ø²Ø² ======================
class VulnerabilityEnv(gym.Env):
    def __init__(self, data_generator):
        super(VulnerabilityEnv, self).__init__()
        
        self.data_generator = data_generator
        self.current_system = None
        self.steps_taken = 0
        self.discovered_ports = []
        self.discovered_services = []
        self.found_vulnerabilities = []
        self.access_level = 0  # 0: Ù„Ø§ ÙŠÙˆØ¬Ø¯ ÙˆØµÙˆÙ„ØŒ 1: ÙˆØµÙˆÙ„ Ø¬Ø²Ø¦ÙŠØŒ 2: ÙˆØµÙˆÙ„ ÙƒØ§Ù…Ù„
        
        # ØªØ¹Ø±ÙŠÙ Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ø­Ø§Ù„Ø©
        self.observation_space = spaces.Box(
            low=0, high=1, shape=(20,), dtype=np.float32
        )
        
        # ØªØ¹Ø±ÙŠÙ Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª
        self.action_space = spaces.Discrete(12)
        
        self.action_descriptions = [
            "Ù…Ø³Ø­ Ø§Ù„Ù…Ù†Ø§ÙØ° Ø§Ù„Ø³Ø±ÙŠØ¹",
            "Ù…Ø³Ø­ Ø§Ù„Ù…Ù†Ø§ÙØ° Ø§Ù„Ø¹Ù…ÙŠÙ‚",
            "ÙØ­Øµ Ø§Ù„Ø®Ø¯Ù…Ø§Øª",
            "Ø§Ø®ØªØ¨Ø§Ø± SQL Injection",
            "Ø§Ø®ØªØ¨Ø§Ø± XSS",
            "Ø§Ø®ØªØ¨Ø§Ø± RCE",
            "Ø§Ø®ØªØ¨Ø§Ø± LFI",
            "Ø§Ø®ØªØ¨Ø§Ø± SSRF",
            "Ø§Ø³ØªØºÙ„Ø§Ù„ Ø§Ù„Ø«ØºØ±Ø©",
            "ØªØµØ¹ÙŠØ¯ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª",
            "ØªØ«Ø¨ÙŠØª ÙˆØµÙˆÙ„",
            "Ø§Ù„Ù…Ø­Ø§ÙØ¸Ø© Ø¹Ù„Ù‰ Ø§Ù„ØªØ®ÙÙŠ"
        ]
        
        self.reset()
    
    def reset(self):
        self.current_system = self.data_generator.generate_system()
        self.steps_taken = 0
        self.discovered_ports = []
        self.discovered_services = []
        self.found_vulnerabilities = []
        self.access_level = 0
        
        return self._get_state()
    
    def _get_state(self):
        state = np.zeros(20, dtype=np.float32)
        
        # Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ´ØºÙŠÙ„ (one-hot encoding)
        os_types = ['Linux', 'Windows', 'macOS']
        if self.current_system['os'] in os_types:
            state[os_types.index(self.current_system['os'])] = 1.0
        
        # Ù†ÙˆØ¹ Ø§Ù„Ù†Ø¸Ø§Ù… (one-hot encoding)
        system_types = list(self.data_generator.systems.keys())
        if self.current_system['type'] in system_types:
            state[3 + system_types.index(self.current_system['type'])] = 1.0
        
        # Ù†Ø³Ø¨Ø© Ø§Ù„Ø§ÙƒØªØ´Ø§Ù
        if self.current_system['open_ports']:
            state[8] = len(self.discovered_ports) / len(self.current_system['open_ports'])
        
        if self.current_system['services']:
            state[9] = len(self.discovered_services) / len(self.current_system['services'])
        
        # Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø£Ù…Ø§Ù†
        state[10] = self.current_system['security_level'] / 10.0
        
        # ÙˆØ¬ÙˆØ¯ Ø¬Ø¯Ø§Ø± Ù†Ø§Ø±ÙŠ
        state[11] = 1.0 if self.current_system['firewall'] else 0.0
        
        # ÙˆØ¬ÙˆØ¯ Ù†Ø¸Ø§Ù… ÙƒØ´Ù
        state[12] = 1.0 if self.current_system['ids'] else 0.0
        
        # Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ÙˆØµÙˆÙ„
        state[13] = self.access_level / 2.0
        
        # Ø¹Ø¯Ø¯ Ø§Ù„Ø®Ø·ÙˆØ§Øª
        state[14] = self.steps_taken / 50.0
        
        # ÙˆØ¬ÙˆØ¯ Ø«ØºØ±Ø©
        state[15] = 1.0 if self.current_system['has_vulnerability'] else 0.0
        
        # Ø¹Ø¯Ø¯ Ø§Ù„Ø«ØºØ±Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©
        state[16] = len(self.found_vulnerabilities) / 3.0
        
        # ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ù†Ø¸Ø§Ù…
        complexity = len(self.current_system['open_ports']) * 0.1
        complexity += len(self.current_system['services']) * 0.1
        state[17] = min(1.0, complexity)
        
        # Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© (Ù„Ø¥Ø¶Ø§ÙØ© ØªÙ†ÙˆØ¹)
        state[18] = random.random()
        state[19] = random.random()
        
        return state
    
    def step(self, action):
        self.steps_taken += 1
        reward = 0
        done = False
        info = {'action': self.action_descriptions[action]}
        
        # ØªÙ†ÙÙŠØ° Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡
        if action == 0:  # Ù…Ø³Ø­ Ø§Ù„Ù…Ù†Ø§ÙØ° Ø§Ù„Ø³Ø±ÙŠØ¹
            reward = self._fast_scan()
        elif action == 1:  # Ù…Ø³Ø­ Ø§Ù„Ù…Ù†Ø§ÙØ° Ø§Ù„Ø¹Ù…ÙŠÙ‚
            reward = self._deep_scan()
        elif action == 2:  # ÙØ­Øµ Ø§Ù„Ø®Ø¯Ù…Ø§Øª
            reward = self._service_scan()
        elif action in [3, 4, 5, 6, 7]:  # Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ø«ØºØ±Ø§Øª
            vuln_type = ['SQL Injection', 'XSS', 'RCE', 'LFI', 'SSRF'][action-3]
            reward = self._test_vulnerability(vuln_type)
        elif action == 8:  # Ø§Ø³ØªØºÙ„Ø§Ù„ Ø§Ù„Ø«ØºØ±Ø©
            reward = self._exploit_vulnerability()
        elif action == 9:  # ØªØµØ¹ÙŠØ¯ Ø§Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª
            reward = self._escalate_privileges()
        elif action == 10:  # ØªØ«Ø¨ÙŠØª ÙˆØµÙˆÙ„
            reward = self._establish_access()
        elif action == 11:  # Ø§Ù„Ù…Ø­Ø§ÙØ¸Ø© Ø¹Ù„Ù‰ Ø§Ù„ØªØ®ÙÙŠ
            reward = self._maintain_stealth()
        
        # Ø¹Ù‚ÙˆØ¨Ø© Ø§Ù„ÙˆÙ‚Øª
        reward -= 0.01
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø­Ù„Ù‚Ø©
        if self.steps_taken >= 50:
            done = True
            # Ù…ÙƒØ§ÙØ£Ø© Ø¥Ø¶Ø§ÙÙŠØ© Ù„Ù„Ø¥Ù†Ø¬Ø§Ø²Ø§Øª
            if len(self.found_vulnerabilities) > 0:
                reward += 1.0
            if self.access_level == 2:
                reward += 2.0
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª
        info['reward'] = reward
        info['steps'] = self.steps_taken
        info['access_level'] = self.access_level
        info['vulnerabilities_found'] = len(self.found_vulnerabilities)
        
        return self._get_state(), reward, done, info
    
    def _fast_scan(self):
        reward = 0
        common_ports = [21, 22, 23, 25, 53, 80, 110, 143, 443, 445, 3389]
        
        for port in common_ports:
            if port in self.current_system['open_ports'] and port not in self.discovered_ports:
                self.discovered_ports.append(port)
                reward += 0.1
        
        return reward
    
    def _deep_scan(self):
        reward = 0
        
        for port in self.current_system['open_ports']:
            if port not in self.discovered_ports:
                self.discovered_ports.append(port)
                reward += 0.05
        
        return reward
    
    def _service_scan(self):
        reward = 0
        
        if len(self.discovered_ports) > 0:
            for service in self.current_system['services']:
                if service not in self.discovered_services:
                    self.discovered_services.append(service)
                    reward += 0.2
        
        return reward
    
    def _test_vulnerability(self, vuln_type):
        reward = 0
        
        if self.current_system['has_vulnerability']:
            if self.current_system['vulnerability']['type'] == vuln_type:
                if vuln_type not in self.found_vulnerabilities:
                    self.found_vulnerabilities.append(vuln_type)
                    reward += 1.0
            else:
                reward -= 0.1  # Ø¹Ù‚ÙˆØ¨Ø© Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø®Ø§Ø·Ø¦
        
        return reward
    
    def _exploit_vulnerability(self):
        reward = 0
        
        if len(self.found_vulnerabilities) > 0:
            if self.current_system['vulnerability']['exploitable']:
                self.access_level = 1
                reward += 2.0
            else:
                reward -= 0.5
        
        return reward
    
    def _escalate_privileges(self):
        reward = 0
        
        if self.access_level == 1:
            if random.random() > 0.5:  # 50% ÙØ±ØµØ© Ù„Ù„Ù†Ø¬Ø§Ø­
                self.access_level = 2
                reward += 3.0
            else:
                reward -= 1.0
        
        return reward
    
    def _establish_access(self):
        reward = 0
        
        if self.access_level == 2:
            reward += 1.0  # Ù…ÙƒØ§ÙØ£Ø© Ø¥Ø¶Ø§ÙÙŠØ© Ù„ØªØ«Ø¨ÙŠØª Ø§Ù„ÙˆØµÙˆÙ„
        
        return reward
    
    def _maintain_stealth(self):
        reward = 0
        
        # ØªÙ‚Ù„ÙŠÙ„ ÙØ±ØµØ© Ø§Ù„Ø§ÙƒØªØ´Ø§Ù
        if random.random() > 0.8:  # 20% ÙØ±ØµØ© Ù„Ù„Ø§ÙƒØªØ´Ø§Ù
            reward += 0.5
        
        return reward
    
    def render(self, mode='human'):
        print(f"\n=== Ù†Ø¸Ø§Ù…: {self.current_system['id']} ===")
        print(f"Ù†ÙˆØ¹ Ø§Ù„Ù†Ø¸Ø§Ù…: {self.current_system['type']}")
        print(f"Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ´ØºÙŠÙ„: {self.current_system['os']}")
        print(f"Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø£Ù…Ø§Ù†: {self.current_system['security_level']}/10")
        print(f"Ø¬Ø¯Ø§Ø± Ù†Ø§Ø±ÙŠ: {'Ù†Ø¹Ù…' if self.current_system['firewall'] else 'Ù„Ø§'}")
        print(f"Ù†Ø¸Ø§Ù… ÙƒØ´Ù: {'Ù†Ø¹Ù…' if self.current_system['ids'] else 'Ù„Ø§'}")
        print(f"Ø§Ù„Ù…Ù†Ø§ÙØ° Ø§Ù„Ù…ÙØªÙˆØ­Ø©: {self.current_system['open_ports']}")
        print(f"Ø§Ù„Ø®Ø¯Ù…Ø§Øª: {self.current_system['services']}")
        print(f"ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø«ØºØ±Ø§Øª: {'Ù†Ø¹Ù…' if self.current_system['has_vulnerability'] else 'Ù„Ø§'}")
        
        if self.current_system['has_vulnerability']:
            print(f"Ù†ÙˆØ¹ Ø§Ù„Ø«ØºØ±Ø©: {self.current_system['vulnerability']['type']}")
            print(f"Ø´Ø¯Ø© Ø§Ù„Ø«ØºØ±Ø©: {self.current_system['vulnerability']['severity']}/10")
        
        print(f"\n=== Ø§Ù„ØªÙ‚Ø¯Ù… ===")
        print(f"Ø§Ù„Ø®Ø·ÙˆØ§Øª: {self.steps_taken}")
        print(f"Ø§Ù„Ù…Ù†Ø§ÙØ° Ø§Ù„Ù…ÙƒØªØ´ÙØ©: {self.discovered_ports}")
        print(f"Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©: {self.discovered_services}")
        print(f"Ø§Ù„Ø«ØºØ±Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©: {self.found_vulnerabilities}")
        print(f"Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ÙˆØµÙˆÙ„: {self.access_level}/2")
        print("="*50)

# ====================== Ø§Ù„Ø´Ø¨ÙƒØ§Øª Ø§Ù„Ø¹ØµØ¨ÙŠØ© ======================
class ActorNetwork(nn.Module):
    def __init__(self, state_size, action_size, hidden_size=256):
        super(ActorNetwork, self).__init__()
        
        self.network = nn.Sequential(
            nn.Linear(state_size, hidden_size),
            nn.ReLU(),
            nn.Linear(hidden_size, hidden_size),
            nn.ReLU(),
            nn.Linear(hidden_size, action_size),
            nn.Softmax(dim=-1)
        )
    
    def forward(self, state):
        return self.network(state)

class CriticNetwork(nn.Module):
    def __init__(self, state_size, hidden_size=256):
        super(CriticNetwork, self).__init__()
        
        self.network = nn.Sequential(
            nn.Linear(state_size, hidden_size),
            nn.ReLU(),
            nn.Linear(hidden_size, hidden_size),
            nn.ReLU(),
            nn.Linear(hidden_size, 1)
        )
    
    def forward(self, state):
        return self.network(state)

# ====================== Ø§Ù„Ø°Ø§ÙƒØ±Ø© ======================
class ReplayMemory:
    def __init__(self, capacity):
        self.capacity = capacity
        self.memory = deque(maxlen=capacity)
    
    def push(self, state, action, reward, next_state, done):
        self.memory.append((state, action, reward, next_state, done))
    
    def sample(self, batch_size):
        if len(self.memory) < batch_size:
            return None
        
        batch = random.sample(self.memory, batch_size)
        states, actions, rewards, next_states, dones = zip(*batch)
        
        return (
            torch.FloatTensor(states),
            torch.LongTensor(actions),
            torch.FloatTensor(rewards),
            torch.FloatTensor(next_states),
            torch.FloatTensor(dones)
        )
    
    def __len__(self):
        return len(self.memory)

# ====================== ÙˆÙƒÙŠÙ„ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø¹Ø²Ø² ======================
class RLAgent:
    def __init__(self, state_size, action_size, config):
        self.state_size = state_size
        self.action_size = action_size
        self.config = config
        
        # Ø§Ù„Ø´Ø¨ÙƒØ§Øª
        self.actor = ActorNetwork(state_size, action_size, config.hidden_size)
        self.critic = CriticNetwork(state_size, config.hidden_size)
        
        # Ø§Ù„Ù…Ø«ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©
        self.target_actor = ActorNetwork(state_size, action_size, config.hidden_size)
        self.target_critic = CriticNetwork(state_size, config.hidden_size)
        
        # Ù†Ø³Ø® Ø§Ù„Ø£ÙˆØ²Ø§Ù†
        self.target_actor.load_state_dict(self.actor.state_dict())
        self.target_critic.load_state_dict(self.critic.state_dict())
        
        # Ø§Ù„Ù…Ø­Ø³Ù†Ø§Øª
        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=config.learning_rate)
        self.critic_optimizer = optim.Adam(self.critic.parameters(), lr=config.learning_rate)
        
        # Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        self.memory = ReplayMemory(config.memory_size)
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        self.epsilon = config.epsilon_start
        self.steps = 0
        self.episodes = 0
        
        # Ù†Ù‚Ù„ Ù„Ù„Ù†Ø¸Ø§Ù… Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ØªØ§Ø­Ø§Ù‹
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.actor.to(self.device)
        self.critic.to(self.device)
        self.target_actor.to(self.device)
        self.target_critic.to(self.device)
    
    def select_action(self, state, training=True):
        state_tensor = torch.FloatTensor(state).unsqueeze(0).to(self.device)
        
        if training and random.random() < self.epsilon:
            # Ø§Ø³ØªÙƒØ´Ø§Ù Ø¹Ø´ÙˆØ§Ø¦ÙŠ
            action = random.randrange(self.action_size)
        else:
            # Ø§Ø³ØªØºÙ„Ø§Ù„
            with torch.no_grad():
                action_probs = self.actor(state_tensor)
                action_dist = Categorical(action_probs)
                action = action_dist.sample().item()
        
        # ØªØ®ÙÙŠØ¶ Ø¥Ø¨Ø³ÙŠÙ„ÙˆÙ†
        if training:
            self.epsilon = max(self.config.epsilon_end, 
                             self.epsilon * self.config.epsilon_decay)
        
        return action
    
    def learn(self):
        if len(self.memory) < self.config.batch_size:
            return 0, 0
        
        # Ø£Ø®Ø° Ø¹ÙŠÙ†Ø© Ù…Ù† Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        batch = self.memory.sample(self.config.batch_size)
        if batch is None:
            return 0, 0
        
        states, actions, rewards, next_states, dones = batch
        
        states = states.to(self.device)
        actions = actions.to(self.device)
        rewards = rewards.to(self.device)
        next_states = next_states.to(self.device)
        dones = dones.to(self.device)
        
        # Ø­Ø³Ø§Ø¨ Ù‚ÙŠÙ… Q Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©
        with torch.no_grad():
            next_action_probs = self.target_actor(next_states)
            next_action_dist = Categorical(next_action_probs)
            next_actions = next_action_dist.sample()
            next_q_values = self.target_critic(next_states).squeeze()
            
            target_q_values = rewards + self.config.gamma * next_q_values * (1 - dones)
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Ø§Ù‚Ø¯
        current_q_values = self.critic(states).squeeze()
        critic_loss = F.mse_loss(current_q_values, target_q_values)
        
        self.critic_optimizer.zero_grad()
        critic_loss.backward()
        torch.nn.utils.clip_grad_norm_(self.critic.parameters(), 1.0)
        self.critic_optimizer.step()
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…Ù…Ø«Ù„
        action_probs = self.actor(states)
        action_dist = Categorical(action_probs)
        action_log_probs = action_dist.log_prob(actions)
        
        actor_loss = -torch.mean(action_log_probs * (target_q_values - current_q_values.detach()))
        
        self.actor_optimizer.zero_grad()
        actor_loss.backward()
        torch.nn.utils.clip_grad_norm_(self.actor.parameters(), 1.0)
        self.actor_optimizer.step()
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø´Ø¨ÙƒØ§Øª Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©
        self._soft_update(self.target_actor, self.actor, self.config.tau)
        self._soft_update(self.target_critic, self.critic, self.config.tau)
        
        return actor_loss.item(), critic_loss.item()
    
    def _soft_update(self, target, source, tau):
        for target_param, param in zip(target.parameters(), source.parameters()):
            target_param.data.copy_(tau * param.data + (1.0 - tau) * target_param.data)
    
    def save_model(self, path):
        torch.save({
            'actor_state_dict': self.actor.state_dict(),
            'critic_state_dict': self.critic.state_dict(),
            'actor_optimizer_state_dict': self.actor_optimizer.state_dict(),
            'critic_optimizer_state_dict': self.critic_optimizer.state_dict(),
            'epsilon': self.epsilon,
            'steps': self.steps,
            'episodes': self.episodes
        }, path)
    
    def load_model(self, path):
        checkpoint = torch.load(path)
        self.actor.load_state_dict(checkpoint['actor_state_dict'])
        self.critic.load_state_dict(checkpoint['critic_state_dict'])
        self.actor_optimizer.load_state_dict(checkpoint['actor_optimizer_state_dict'])
        self.critic_optimizer.load_state_dict(checkpoint['critic_optimizer_state_dict'])
        self.epsilon = checkpoint['epsilon']
        self.steps = checkpoint['steps']
        self.episodes = checkpoint['episodes']
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø´Ø¨ÙƒØ§Øª Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©
        self.target_actor.load_state_dict(self.actor.state_dict())
        self.target_critic.load_state_dict(self.critic.state_dict())

# ====================== Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø°Ø§ØªÙŠ Ø§Ù„ØªØ¹Ù„Ù… ======================
class AutonomousLearningSystem:
    def __init__(self):
        self.config = SystemConfig()
        self.data_generator = DataGenerator()
        self.env = VulnerabilityEnv(self.data_generator)
        
        state_size = self.env.observation_space.shape[0]
        action_size = self.env.action_space.n
        
        self.agent = RLAgent(state_size, action_size, self.config)
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        self.training_stats = {
            'episode_rewards': [],
            'episode_lengths': [],
            'losses': [],
            'epsilon_values': [],
            'success_rate': []
        }
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø³Ø¬Ù„
        self.setup_logging()
    
    def setup_logging(self):
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('logs/training.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)
    
    def train(self, num_episodes=None):
        if num_episodes is None:
            num_episodes = self.config.max_episodes
        
        self.logger.info(f"Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù„Ù€ {num_episodes} Ø­Ù„Ù‚Ø©")
        
        for episode in range(num_episodes):
            state = self.env.reset()
            episode_reward = 0
            episode_loss = 0
            steps = 0
            
            for step in range(self.config.max_steps):
                # Ø§Ø®ØªÙŠØ§Ø± Ø¥Ø¬Ø±Ø§Ø¡
                action = self.agent.select_action(state, training=True)
                
                # ØªÙ†ÙÙŠØ° Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡
                next_state, reward, done, info = self.env.step(action)
                
                # Ø­ÙØ¸ Ø§Ù„Ø®Ø¨Ø±Ø©
                self.agent.memory.push(state, action, reward, next_state, done)
                
                # Ø§Ù„ØªØ¹Ù„Ù…
                actor_loss, critic_loss = self.agent.learn()
                if actor_loss > 0:
                    episode_loss += actor_loss + critic_loss
                
                # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ø§Ù„Ø©
                state = next_state
                episode_reward += reward
                steps += 1
                self.agent.steps += 1
                
                if done:
                    break
            
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
            self.training_stats['episode_rewards'].append(episode_reward)
            self.training_stats['episode_lengths'].append(steps)
            self.training_stats['epsilon_values'].append(self.agent.epsilon)
            self.training_stats['losses'].append(episode_loss / max(steps, 1))
            
            # Ø­Ø³Ø§Ø¨ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­
            success = 1 if episode_reward > 10 else 0
            if len(self.training_stats['success_rate']) < 10:
                self.training_stats['success_rate'].append(success)
            else:
                self.training_stats['success_rate'].pop(0)
                self.training_stats['success_rate'].append(success)
            
            self.agent.episodes += 1
            
            # Ø¹Ø±Ø¶ Ø§Ù„ØªÙ‚Ø¯Ù…
            if (episode + 1) % 10 == 0:
                avg_reward = np.mean(self.training_stats['episode_rewards'][-10:])
                avg_steps = np.mean(self.training_stats['episode_lengths'][-10:])
                success_rate = np.mean(self.training_stats['success_rate']) * 100
                
                self.logger.info(
                    f"Ø§Ù„Ø­Ù„Ù‚Ø© {episode + 1:4d} | "
                    f"Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ÙƒØ§ÙØ£Ø©: {avg_reward:6.2f} | "
                    f"Ù…ØªÙˆØ³Ø· Ø§Ù„Ø®Ø·ÙˆØ§Øª: {avg_steps:5.1f} | "
                    f"Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­: {success_rate:5.1f}% | "
                    f"Ø¥Ø¨Ø³ÙŠÙ„ÙˆÙ†: {self.agent.epsilon:.3f}"
                )
            
            # Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            if (episode + 1) % self.config.save_every == 0:
                model_path = f"models/agent_episode_{episode + 1}.pth"
                self.agent.save_model(model_path)
                self.data_generator.save_patterns()
                self.save_training_stats()
                
                self.logger.info(f"ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ {model_path}")
        
        # Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        final_path = "models/agent_final.pth"
        self.agent.save_model(final_path)
        self.data_generator.save_patterns()
        self.save_training_stats()
        self.plot_training_results()
        
        self.logger.info(f"Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨! ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ÙÙŠ {final_path}")
    
    def test(self, num_episodes=100, render=False):
        self.logger.info(f"Ø¨Ø¯Ø¡ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ù„Ù€ {num_episodes} Ø­Ù„Ù‚Ø©")
        
        test_stats = {
            'rewards': [],
            'steps': [],
            'vulnerabilities_found': [],
            'access_levels': [],
            'successful_episodes': 0
        }
        
        for episode in range(num_episodes):
            state = self.env.reset()
            episode_reward = 0
            steps = 0
            max_access = 0
            vulnerabilities_found = 0
            
            for step in range(self.config.max_steps):
                # Ø§Ø®ØªÙŠØ§Ø± Ø¥Ø¬Ø±Ø§Ø¡ (Ø¨Ø¯ÙˆÙ† Ø§Ø³ØªÙƒØ´Ø§Ù)
                action = self.agent.select_action(state, training=False)
                
                # ØªÙ†ÙÙŠØ° Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡
                next_state, reward, done, info = self.env.step(action)
                
                # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
                episode_reward += reward
                steps += 1
                max_access = max(max_access, info['access_level'])
                vulnerabilities_found = max(vulnerabilities_found, info['vulnerabilities_found'])
                
                if render:
                    self.env.render()
                    print(f"Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡: {info['action']}")
                    print(f"Ø§Ù„Ù…ÙƒØ§ÙØ£Ø©: {reward:.2f}")
                    time.sleep(0.1)
                
                if done:
                    break
            
            # ØªØ­Ø¯ÙŠØ« Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
            test_stats['rewards'].append(episode_reward)
            test_stats['steps'].append(steps)
            test_stats['vulnerabilities_found'].append(vulnerabilities_found)
            test_stats['access_levels'].append(max_access)
            
            if episode_reward > 15:  # Ø¹ØªØ¨Ø© Ø§Ù„Ù†Ø¬Ø§Ø­
                test_stats['successful_episodes'] += 1
        
        # Ø¹Ø±Ø¶ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
        print("\n" + "="*60)
        print("Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±")
        print("="*60)
        print(f"Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ù„Ù‚Ø§Øª: {num_episodes}")
        print(f"Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ÙƒØ§ÙØ£Ø©: {np.mean(test_stats['rewards']):.2f}")
        print(f"Ù…ØªÙˆØ³Ø· Ø§Ù„Ø®Ø·ÙˆØ§Øª: {np.mean(test_stats['steps']):.2f}")
        print(f"Ù…ØªÙˆØ³Ø· Ø§Ù„Ø«ØºØ±Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©: {np.mean(test_stats['vulnerabilities_found']):.2f}")
        print(f"Ù…ØªÙˆØ³Ø· Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ÙˆØµÙˆÙ„: {np.mean(test_stats['access_levels']):.2f}")
        print(f"Ø§Ù„Ø­Ù„Ù‚Ø§Øª Ø§Ù„Ù†Ø§Ø¬Ø­Ø©: {test_stats['successful_episodes']} ({test_stats['successful_episodes']/num_episodes*100:.1f}%)")
        print("="*60)
        
        # Ø­ÙØ¸ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
        with open('reports/test_results.txt', 'w') as f:
            f.write("Ù†ØªØ§Ø¦Ø¬ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø°Ø§ØªÙŠ Ø§Ù„ØªØ¹Ù„Ù…\n")
            f.write("="*50 + "\n")
            f.write(f"Ø§Ù„ØªØ§Ø±ÙŠØ®: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ù„Ù‚Ø§Øª: {num_episodes}\n")
            f.write(f"Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ÙƒØ§ÙØ£Ø©: {np.mean(test_stats['rewards']):.2f}\n")
            f.write(f"Ù…ØªÙˆØ³Ø· Ø§Ù„Ø®Ø·ÙˆØ§Øª: {np.mean(test_stats['steps']):.2f}\n")
            f.write(f"Ù…ØªÙˆØ³Ø· Ø§Ù„Ø«ØºØ±Ø§Øª: {np.mean(test_stats['vulnerabilities_found']):.2f}\n")
            f.write(f"Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­: {test_stats['successful_episodes']/num_episodes*100:.1f}%\n")
        
        return test_stats
    
    def save_training_stats(self):
        stats = {
            'training_stats': self.training_stats,
            'config': self.config.__dict__,
            'timestamp': datetime.now().isoformat()
        }
        
        with open('data/training_stats.pkl', 'wb') as f:
            pickle.dump(stats, f)
    
    def load_training_stats(self):
        if os.path.exists('data/training_stats.pkl'):
            with open('data/training_stats.pkl', 'rb') as f:
                stats = pickle.load(f)
                self.training_stats = stats['training_stats']
    
    def plot_training_results(self):
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        
        # Ø§Ù„Ù…ÙƒØ§ÙØ¢Øª
        axes[0, 0].plot(self.training_stats['episode_rewards'])
        axes[0, 0].set_title('Ø§Ù„Ù…ÙƒØ§ÙØ¢Øª ÙÙŠ ÙƒÙ„ Ø­Ù„Ù‚Ø©')
        axes[0, 0].set_xlabel('Ø§Ù„Ø­Ù„Ù‚Ø©')
        axes[0, 0].set_ylabel('Ø§Ù„Ù…ÙƒØ§ÙØ£Ø©')
        axes[0, 0].grid(True)
        
        # Ù…ØªÙˆØ³Ø· Ù…ØªØ­Ø±Ùƒ Ù„Ù„Ù…ÙƒØ§ÙØ¢Øª
        window = 50
        if len(self.training_stats['episode_rewards']) >= window:
            moving_avg = np.convolve(self.training_stats['episode_rewards'], 
                                    np.ones(window)/window, mode='valid')
            axes[0, 1].plot(moving_avg)
            axes[0, 1].set_title(f'Ù…ØªÙˆØ³Ø· Ù…ØªØ­Ø±Ùƒ Ù„Ù„Ù…ÙƒØ§ÙØ¢Øª (Ù†Ø§ÙØ°Ø© {window})')
            axes[0, 1].set_xlabel('Ø§Ù„Ø­Ù„Ù‚Ø©')
            axes[0, 1].set_ylabel('Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ÙƒØ§ÙØ£Ø©')
            axes[0, 1].grid(True)
        
        # Ø·ÙˆÙ„ Ø§Ù„Ø­Ù„Ù‚Ø§Øª
        axes[0, 2].plot(self.training_stats['episode_lengths'])
        axes[0, 2].set_title('Ø·ÙˆÙ„ Ø§Ù„Ø­Ù„Ù‚Ø§Øª')
        axes[0, 2].set_xlabel('Ø§Ù„Ø­Ù„Ù‚Ø©')
        axes[0, 2].set_ylabel('Ø¹Ø¯Ø¯ Ø§Ù„Ø®Ø·ÙˆØ§Øª')
        axes[0, 2].grid(True)
        
        # Ø§Ù„Ø®Ø³Ø§Ø¦Ø±
        axes[1, 0].plot(self.training_stats['losses'])
        axes[1, 0].set_title('Ø§Ù„Ø®Ø³Ø§Ø¦Ø±')
        axes[1, 0].set_xlabel('Ø§Ù„Ø­Ù„Ù‚Ø©')
        axes[1, 0].set_ylabel('Ø§Ù„Ø®Ø³Ø§Ø±Ø©')
        axes[1, 0].grid(True)
        
        # Ø¥Ø¨Ø³ÙŠÙ„ÙˆÙ†
        axes[1, 1].plot(self.training_stats['epsilon_values'])
        axes[1, 1].set_title('Ù‚ÙŠÙ…Ø© Ø¥Ø¨Ø³ÙŠÙ„ÙˆÙ†')
        axes[1, 1].set_xlabel('Ø§Ù„Ø­Ù„Ù‚Ø©')
        axes[1, 1].set_ylabel('Ø¥Ø¨Ø³ÙŠÙ„ÙˆÙ†')
        axes[1, 1].grid(True)
        
        # Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­
        if self.training_stats['success_rate']:
            success_rates = []
            for i in range(len(self.training_stats['success_rate'])):
                if i >= 9:
                    avg = np.mean(self.training_stats['success_rate'][i-9:i+1]) * 100
                    success_rates.append(avg)
            
            axes[1, 2].plot(success_rates)
            axes[1, 2].set_title('Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­')
            axes[1, 2].set_xlabel('Ø§Ù„Ø­Ù„Ù‚Ø©')
            axes[1, 2].set_ylabel('Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­ (%)')
            axes[1, 2].grid(True)
        
        plt.tight_layout()
        plt.savefig('reports/training_results.png', dpi=300, bbox_inches='tight')
        plt.show()

# ====================== ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ======================
class UserInterface:
    def __init__(self):
        self.system = None
        self.model_loaded = False
    
    def show_menu(self):
        print("\n" + "="*60)
        print("Ù†Ø¸Ø§Ù… Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø«ØºØ±Ø§Øª Ø§Ù„Ø£Ù…Ù†ÙŠØ© Ø§Ù„Ø°Ø§ØªÙŠ Ø§Ù„ØªØ¹Ù„Ù…")
        print("="*60)
        print("1. ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ø¸Ø§Ù… Ù…Ù† Ø§Ù„ØµÙØ±")
        print("2. Ø§Ø³ØªØ¦Ù†Ø§Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨")
        print("3. Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨")
        print("4. Ø¹Ø±Ø¶ ØªÙˆØ¶ÙŠØ­ÙŠ Ù„Ù„Ù†Ø¸Ø§Ù…")
        print("5. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª")
        print("6. Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©")
        print("7. ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¯Ø±Ø¨")
        print("8. Ø§Ù„Ø®Ø±ÙˆØ¬")
        print("="*60)
    
    def run(self):
        while True:
            self.show_menu()
            choice = input("\nØ§Ø®ØªØ± Ø±Ù‚Ù… Ø§Ù„Ø®ÙŠØ§Ø±: ").strip()
            
            try:
                if choice == '1':
                    self.train_from_scratch()
                elif choice == '2':
                    self.resume_training()
                elif choice == '3':
                    self.test_model()
                elif choice == '4':
                    self.run_demo()
                elif choice == '5':
                    self.analyze_data()
                elif choice == '6':
                    self.create_backup()
                elif choice == '7':
                    self.load_model()
                elif choice == '8':
                    print("\nØ´ÙƒØ±Ø§Ù‹ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø°Ø§ØªÙŠ Ø§Ù„ØªØ¹Ù„Ù…!")
                    break
                else:
                    print("âš ï¸ Ø®ÙŠØ§Ø± ØºÙŠØ± ØµØ­ÙŠØ­ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰")
            except KeyboardInterrupt:
                print("\n\nØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù†Ø¸Ø§Ù… Ù…Ù† Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…")
                break
            except Exception as e:
                print(f"\nâŒ Ø­Ø¯Ø« Ø®Ø·Ø£: {str(e)}")
                print("ÙŠØ±Ø¬Ù‰ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ù…Ø±Ø© Ø£Ø®Ø±Ù‰")
    
    def train_from_scratch(self):
        print("\nğŸ¯ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…Ù† Ø§Ù„ØµÙØ±")
        episodes = input("Ø¹Ø¯Ø¯ Ø­Ù„Ù‚Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (Ø§ÙØªØ±Ø§Ø¶ÙŠ: 1000): ").strip()
        
        try:
            num_episodes = int(episodes) if episodes else 1000
        except:
            num_episodes = 1000
        
        confirm = input(f"\nÙ‡Ù„ ØªØ±ÙŠØ¯ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù„Ù€ {num_episodes} Ø­Ù„Ù‚Ø©ØŸ (Ù†Ø¹Ù…/Ù„Ø§): ").strip().lower()
        
        if confirm in ['Ù†Ø¹Ù…', 'yes', 'y', '1']:
            self.system = AutonomousLearningSystem()
            print(f"\nâ³ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù„Ù€ {num_episodes} Ø­Ù„Ù‚Ø©...")
            print("Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ Ù‡Ø°Ø§ Ø¨Ø¹Ø¶ Ø§Ù„ÙˆÙ‚Øª...")
            
            start_time = time.time()
            self.system.train(num_episodes)
            end_time = time.time()
            
            duration = end_time - start_time
            hours = int(duration // 3600)
            minutes = int((duration % 3600) // 60)
            seconds = int(duration % 60)
            
            print(f"\nâœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙÙŠ {hours:02d}:{minutes:02d}:{seconds:02d}")
            self.model_loaded = True
        else:
            print("âŒ ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨")
    
    def resume_training(self):
        model_path = input("\nÙ…Ø³Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„Ø§Ø³ØªØ¦Ù†Ø§Ù (Ø§ÙØªØ±Ø§Ø¶ÙŠ: models/agent_final.pth): ").strip()
        if not model_path:
            model_path = "models/agent_final.pth"
        
        if not os.path.exists(model_path):
            print(f"âŒ Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {model_path}")
            return
        
        episodes = input("Ø¹Ø¯Ø¯ Ø­Ù„Ù‚Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ© (Ø§ÙØªØ±Ø§Ø¶ÙŠ: 500): ").strip()
        
        try:
            num_episodes = int(episodes) if episodes else 500
        except:
            num_episodes = 500
        
        confirm = input(f"\nÙ‡Ù„ ØªØ±ÙŠØ¯ Ø§Ø³ØªØ¦Ù†Ø§Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù„Ù€ {num_episodes} Ø­Ù„Ù‚Ø© Ø¥Ø¶Ø§ÙÙŠØ©ØŸ (Ù†Ø¹Ù…/Ù„Ø§): ").strip().lower()
        
        if confirm in ['Ù†Ø¹Ù…', 'yes', 'y', '1']:
            self.system = AutonomousLearningSystem()
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            if os.path.exists(model_path):
                self.system.agent.load_model(model_path)
                self.system.load_training_stats()
                print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† {model_path}")
            
            print(f"\nâ³ Ø§Ø³ØªØ¦Ù†Ø§Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù„Ù€ {num_episodes} Ø­Ù„Ù‚Ø© Ø¥Ø¶Ø§ÙÙŠØ©...")
            
            start_time = time.time()
            self.system.train(num_episodes)
            end_time = time.time()
            
            duration = end_time - start_time
            hours = int(duration // 3600)
            minutes = int((duration % 3600) // 60)
            seconds = int(duration % 60)
            
            print(f"\nâœ… Ø§ÙƒØªÙ…Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙÙŠ {hours:02d}:{minutes:02d}:{seconds:02d}")
            self.model_loaded = True
        else:
            print("âŒ ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨")
    
    def test_model(self):
        if not self.model_loaded:
            self.load_model()
            if not self.model_loaded:
                return
        
        episodes = input("\nØ¹Ø¯Ø¯ Ø­Ù„Ù‚Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± (Ø§ÙØªØ±Ø§Ø¶ÙŠ: 100): ").strip()
        
        try:
            num_episodes = int(episodes) if episodes else 100
        except:
            num_episodes = 100
        
        render = input("Ù‡Ù„ ØªØ±ÙŠØ¯ Ù…Ø´Ø§Ù‡Ø¯Ø© Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±ØŸ (Ù†Ø¹Ù…/Ù„Ø§): ").strip().lower()
        render_mode = render in ['Ù†Ø¹Ù…', 'yes', 'y', '1']
        
        print(f"\nğŸ”¬ Ø¨Ø¯Ø¡ Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù€ {num_episodes} Ø­Ù„Ù‚Ø©...")
        
        start_time = time.time()
        results = self.system.test(num_episodes, render_mode)
        end_time = time.time()
        
        duration = end_time - start_time
        minutes = int(duration // 60)
        seconds = int(duration % 60)
        
        print(f"\nâ±ï¸  ÙˆÙ‚Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±: {minutes:02d}:{seconds:02d}")
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        if results:
            print("\nğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù…ÙØµÙ„Ø©:")
            print(f"  Ø£Ø¹Ù„Ù‰ Ù…ÙƒØ§ÙØ£Ø©: {np.max(results['rewards']):.2f}")
            print(f"  Ø£Ù‚Ù„ Ù…ÙƒØ§ÙØ£Ø©: {np.min(results['rewards']):.2f}")
            print(f"  Ø§Ù†Ø­Ø±Ø§Ù Ù…Ø¹ÙŠØ§Ø±ÙŠ: {np.std(results['rewards']):.2f}")
            print(f"  Ø£Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ ÙˆØµÙˆÙ„: {np.max(results['access_levels'])}")
            print(f"  Ø£ÙƒØ«Ø± Ø¹Ø¯Ø¯ Ø«ØºØ±Ø§Øª: {np.max(results['vulnerabilities_found'])}")
    
    def run_demo(self):
        print("\nğŸ® Ø¨Ø¯Ø¡ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠ")
        print("Ø³ÙŠØ¹Ø±Ø¶ Ø§Ù„Ù†Ø¸Ø§Ù… 5 Ø­Ù„Ù‚Ø§Øª Ù…Ù† Ø§Ù„ØªÙØ§Ø¹Ù„ Ù…Ø¹ Ø§Ù„Ø£Ù†Ø¸Ù…Ø©")
        
        if not self.model_loaded:
            print("âš ï¸ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§ÙØªØ±Ø§Ø¶ÙŠ...")
            self.system = AutonomousLearningSystem()
            self.model_loaded = True
        
        for demo_num in range(5):
            print(f"\n{'='*60}")
            print(f"Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠ {demo_num + 1}/5")
            print(f"{'='*60}")
            
            state = self.system.env.reset()
            total_reward = 0
            step = 0
            
            self.system.env.render()
            
            for _ in range(20):  # 20 Ø®Ø·ÙˆØ© ÙƒØ­Ø¯ Ø£Ù‚ØµÙ‰ Ù„Ù„Ø¹Ø±Ø¶
                action = self.system.agent.select_action(state, training=False)
                next_state, reward, done, info = self.system.env.step(action)
                
                print(f"\nØ§Ù„Ø®Ø·ÙˆØ© {step + 1}:")
                print(f"  Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡: {info['action']}")
                print(f"  Ø§Ù„Ù…ÙƒØ§ÙØ£Ø©: {reward:.2f}")
                print(f"  Ø§Ù„Ø«ØºØ±Ø§Øª Ø§Ù„Ù…ÙƒØªØ´ÙØ©: {info['vulnerabilities_found']}")
                print(f"  Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ÙˆØµÙˆÙ„: {info['access_level']}")
                
                state = next_state
                total_reward += reward
                step += 1
                
                time.sleep(0.5)
                
                if done:
                    break
            
            print(f"\nÙ†ØªÙŠØ¬Ø© Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠ {demo_num + 1}:")
            print(f"  Ø§Ù„Ù…ÙƒØ§ÙØ£Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©: {total_reward:.2f}")
            print(f"  Ø¹Ø¯Ø¯ Ø§Ù„Ø®Ø·ÙˆØ§Øª: {step}")
            
            if demo_num < 4:
                input("\nâ†µ Ø§Ø¶ØºØ· Enter Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø© Ø¥Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªØ§Ù„ÙŠ...")
        
        print(f"\n{'='*60}")
        print("Ø§Ù†ØªÙ‡Ù‰ Ø§Ù„Ø¹Ø±Ø¶ Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠ!")
        print(f"{'='*60}")
    
    def analyze_data(self):
        print("\nğŸ“ˆ ØªØ­Ù„ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…")
        
        # ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        data_files = []
        if os.path.exists('data/training_stats.pkl'):
            data_files.append('Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨')
        if os.path.exists('data/patterns.json'):
            data_files.append('Ø£Ù†Ù…Ø§Ø· Ø§Ù„ØªØ¹Ù„Ù…')
        if os.path.exists('reports/test_results.txt'):
            data_files.append('Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±')
        if os.path.exists('logs/training.log'):
            data_files.append('Ø³Ø¬Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨')
        
        if not data_files:
            print("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ­Ù„ÙŠÙ„")
            return
        
        print("Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:")
        for i, file in enumerate(data_files, 1):
            print(f"  {i}. {file}")
        
        try:
            choice = input("\nØ§Ø®ØªØ± Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ­Ù„ÙŠÙ„ (Ø±Ù‚Ù…): ").strip()
            choice = int(choice) - 1
            
            if choice < 0 or choice >= len(data_files):
                print("âŒ Ø§Ø®ØªÙŠØ§Ø± ØºÙŠØ± ØµØ­ÙŠØ­")
                return
            
            selected_file = data_files[choice]
            
            if selected_file == 'Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨':
                self.analyze_training_stats()
            elif selected_file == 'Ø£Ù†Ù…Ø§Ø· Ø§Ù„ØªØ¹Ù„Ù…':
                self.analyze_patterns()
            elif selected_file == 'Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±':
                self.analyze_test_results()
            elif selected_file == 'Ø³Ø¬Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨':
                self.analyze_training_log()
        
        except ValueError:
            print("âŒ ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ø±Ù‚Ù… ØµØ­ÙŠØ­")
    
    def analyze_training_stats(self):
        if not os.path.exists('data/training_stats.pkl'):
            print("âŒ Ù…Ù„Ù Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
            return
        
        with open('data/training_stats.pkl', 'rb') as f:
            stats = pickle.load(f)
        
        training_stats = stats['training_stats']
        
        print("\nğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨:")
        print(f"  Ø¹Ø¯Ø¯ Ø§Ù„Ø­Ù„Ù‚Ø§Øª: {len(training_stats['episode_rewards'])}")
        print(f"  Ù…ØªÙˆØ³Ø· Ø§Ù„Ù…ÙƒØ§ÙØ£Ø©: {np.mean(training_stats['episode_rewards']):.2f}")
        print(f"  Ø£ÙØ¶Ù„ Ù…ÙƒØ§ÙØ£Ø©: {np.max(training_stats['episode_rewards']):.2f}")
        print(f"  Ù…ØªÙˆØ³Ø· Ø·ÙˆÙ„ Ø§Ù„Ø­Ù„Ù‚Ø©: {np.mean(training_stats['episode_lengths']):.2f}")
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù†Ø¸Ø§Ù… Ù…ØªØ§Ø­Ø§Ù‹
        if self.system:
            self.system.plot_training_results()
        else:
            print("âš ï¸ ÙŠØªØ·Ù„Ø¨ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù… Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©")
    
    def analyze_patterns(self):
        if not os.path.exists('data/patterns.json'):
            print("âŒ Ù…Ù„Ù Ø§Ù„Ø£Ù†Ù…Ø§Ø· ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
            return
        
        with open('data/patterns.json', 'r') as f:
            patterns = json.load(f)
        
        print(f"\nğŸ“š ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…ÙƒØªØ³Ø¨Ø©:")
        print(f"  Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ù†Ù…Ø§Ø·: {len(patterns)}")
        
        if patterns:
            # ØªØ­Ù„ÙŠÙ„ ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ù†Ø¸Ù…Ø©
            system_counts = {}
            vulnerability_counts = {}
            
            for pattern in patterns:
                system = pattern['system_type']
                vuln = pattern['vulnerability']
                
                system_counts[system] = system_counts.get(system, 0) + 1
                vulnerability_counts[vuln] = vulnerability_counts.get(vuln, 0) + 1
            
            print(f"\n  ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ù†Ø¸Ù…Ø©:")
            for system, count in system_counts.items():
                percentage = (count / len(patterns)) * 100
                print(f"    â€¢ {system}: {count} ({percentage:.1f}%)")
            
            print(f"\n  ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø«ØºØ±Ø§Øª:")
            for vuln, count in vulnerability_counts.items():
                percentage = (count / len(patterns)) * 100
                print(f"    â€¢ {vuln}: {count} ({percentage:.1f}%)")
    
    def analyze_test_results(self):
        if not os.path.exists('reports/test_results.txt'):
            print("âŒ Ù…Ù„Ù Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
            return
        
        with open('reports/test_results.txt', 'r') as f:
            content = f.read()
        
        print("\nğŸ“‹ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±:")
        print(content)
    
    def analyze_training_log(self):
        if not os.path.exists('logs/training.log'):
            print("âŒ Ù…Ù„Ù Ø³Ø¬Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
            return
        
        with open('logs/training.log', 'r') as f:
            lines = f.readlines()
        
        if not lines:
            print("âŒ Ø³Ø¬Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙØ§Ø±Øº")
            return
        
        print(f"\nğŸ“ Ø¢Ø®Ø± 10 Ø³Ø¬Ù„Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨:")
        for line in lines[-10:]:
            print(f"  {line.strip()}")
    
    def create_backup(self):
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_dir = f"backups/backup_{timestamp}"
        
        os.makedirs(backup_dir, exist_ok=True)
        
        # Ù†Ø³Ø® Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ù‡Ù…Ø©
        folders_to_backup = ['models', 'data', 'logs', 'reports']
        
        print(f"\nğŸ’¾ Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© ÙÙŠ: {backup_dir}")
        
        for folder in folders_to_backup:
            if os.path.exists(folder):
                dest_folder = os.path.join(backup_dir, folder)
                shutil.copytree(folder, dest_folder)
                print(f"  âœ… ØªÙ… Ù†Ø³Ø®: {folder}")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
        info = {
            'timestamp': timestamp,
            'date': datetime.now().isoformat(),
            'folders_backed_up': folders_to_backup,
            'system': 'Autonomous Vulnerability Detection System'
        }
        
        with open(os.path.join(backup_dir, 'backup_info.json'), 'w') as f:
            json.dump(info, f, indent=2)
        
        print(f"\nâœ… Ø§ÙƒØªÙ…Ù„Øª Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {backup_dir}")
    
    def load_model(self):
        model_path = input("\nÙ…Ø³Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„ØªØ­Ù…ÙŠÙ„ (Ø§ÙØªØ±Ø§Ø¶ÙŠ: models/agent_final.pth): ").strip()
        if not model_path:
            model_path = "models/agent_final.pth"
        
        if not os.path.exists(model_path):
            print(f"âŒ Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {model_path}")
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø©
            model_files = [f for f in os.listdir('models') if f.endswith('.pth')]
            if model_files:
                print("\nØ§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø©:")
                for i, file in enumerate(model_files, 1):
                    print(f"  {i}. {file}")
                
                try:
                    choice = input("\nØ§Ø®ØªØ± Ø±Ù‚Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù„ØªØ­Ù…ÙŠÙ„: ").strip()
                    choice = int(choice) - 1
                    
                    if 0 <= choice < len(model_files):
                        model_path = os.path.join('models', model_files[choice])
                    else:
                        print("âŒ Ø§Ø®ØªÙŠØ§Ø± ØºÙŠØ± ØµØ­ÙŠØ­")
                        return
                except ValueError:
                    print("âŒ ÙŠØ±Ø¬Ù‰ Ø¥Ø¯Ø®Ø§Ù„ Ø±Ù‚Ù… ØµØ­ÙŠØ­")
                    return
            else:
                print("âŒ Ù„Ø§ ØªÙˆØ¬Ø¯ Ù†Ù…Ø§Ø°Ø¬ Ù…ØªØ§Ø­Ø©")
                return
        
        try:
            self.system = AutonomousLearningSystem()
            self.system.agent.load_model(model_path)
            self.system.load_training_stats()
            
            print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ù†Ø¬Ø§Ø­ Ù…Ù† {model_path}")
            print(f"   Ø§Ù„Ø­Ù„Ù‚Ø§Øª Ø§Ù„Ù…Ø¯Ø±Ø¨Ø©: {self.system.agent.episodes}")
            print(f"   Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„ÙƒÙ„ÙŠØ©: {self.system.agent.steps}")
            print(f"   Ù‚ÙŠÙ…Ø© Ø¥Ø¨Ø³ÙŠÙ„ÙˆÙ†: {self.system.agent.epsilon:.3f}")
            
            self.model_loaded = True
        
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {str(e)}")
            self.model_loaded = False

# ====================== Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ======================
def main():
    print("\n" + "="*70)
    print("ğŸš€ Ù†Ø¸Ø§Ù… Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø«ØºØ±Ø§Øª Ø§Ù„Ø£Ù…Ù†ÙŠØ© Ø§Ù„Ø°Ø§ØªÙŠ Ø§Ù„ØªØ¹Ù„Ù…")
    print("ğŸ“ Ù…Ø´Ø±ÙˆØ¹ ØªØ®Ø±Ø¬ Ù…ØªÙ‚Ø¯Ù… - Ø§Ù„Ø¥ØµØ¯Ø§Ø± 1.0")
    print("ğŸ“… ØªÙ… Ø§Ù„ØªØ·ÙˆÙŠØ±: " + datetime.now().strftime("%Y-%m-%d"))
    print("="*70)
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
    try:
        import torch
        import gym
        import numpy as np
        import pandas as pd
        
        print("âœ… Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù…Ø«Ø¨ØªØ©")
        
        # Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
        print(f"\nğŸ’» Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…:")
        print(f"  Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ´ØºÙŠÙ„: {sys.platform}")
        print(f"  Ø¥ØµØ¯Ø§Ø± Python: {sys.version[:6]}")
        print(f"  PyTorch: {torch.__version__}")
        print(f"  CUDA Ù…ØªØ§Ø­Ø©: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            print(f"  Ø¬Ù‡Ø§Ø² GPU: {torch.cuda.get_device_name(0)}")
    
    except ImportError as e:
        print(f"âŒ Ù…ÙƒØªØ¨Ø© Ù…ÙÙ‚ÙˆØ¯Ø©: {e}")
        print("ÙŠØ±Ø¬Ù‰ ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù…:")
        print("pip install torch gym numpy pandas matplotlib seaborn")
        return
    
    # Ø¨Ø¯Ø¡ ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    ui = UserInterface()
    ui.run()

# ====================== ØªØ´ØºÙŠÙ„ Ø§Ù„Ù†Ø¸Ø§Ù… ======================
if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nØªÙ… Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù†Ø¸Ø§Ù… Ù…Ù† Ù‚Ø¨Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…")
    except Exception as e:
        print(f"\nâŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹: {str(e)}")
        print("ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ù„Ù…ÙƒØªØ¨Ø§Øª")
    finally:
        print("\n" + "="*70)
        print("Ø´ÙƒØ±Ø§Ù‹ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ø¸Ø§Ù… Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø«ØºØ±Ø§Øª Ø§Ù„Ø°Ø§ØªÙŠ Ø§Ù„ØªØ¹Ù„Ù…")
        print("="*70)